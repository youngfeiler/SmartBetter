{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a5f9b5f-7f90-4c7a-b099-dd4fe78403bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import pyarrow as pa\n",
    "import numpy as np\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f3e4ad16-e7c3-4b32-ba25-46e3df59e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the raw data file\n",
    "df = pd.read_parquet('/Users/stefanfeiler/Desktop/SmartBetter/SmartBetter/data/mlb_raw_final_for_model.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f4276f2c-0563-4b80-a45e-2202a319fd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop('home_away', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "eb00abfc-1ea5-4005-ae34-5a9e1cd890d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to seperate 80% of games and 20% of games for test and train splits and then confirm their counts are proportional to those values \n",
    "\n",
    "# Step 1: Get a list of unique groups\n",
    "groups = list(df.groupby('game_id').groups.keys())\n",
    "\n",
    "# Step 2: Shuffle the list of unique groups randomly\n",
    "random.shuffle(groups)\n",
    "\n",
    "# Step 3: Calculate the number of groups for the 20% DataFrame and the 80% DataFrame\n",
    "n_groups_20_percent = int(len(groups) * 0.2)\n",
    "n_groups_80_percent = len(groups) - n_groups_20_percent\n",
    "\n",
    "# Step 4: Use the loc accessor to select rows for each group and add them to the appropriate DataFrame\n",
    "df_20_percent = pd.DataFrame()\n",
    "df_80_percent = pd.DataFrame()\n",
    "\n",
    "for i, group in enumerate(groups):\n",
    "    if i < n_groups_20_percent:\n",
    "        df_20_percent = pd.concat([df_20_percent, df.loc[df['game_id'] == group]])\n",
    "    else:\n",
    "        df_80_percent = pd.concat([df_80_percent, df.loc[df['game_id'] == group]])\n",
    "\n",
    "# Optional: Reset the index of the resulting DataFrames\n",
    "df_20_percent = df_20_percent.reset_index(drop=True)\n",
    "df_80_percent = df_80_percent.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4f120a84-c838-4a12-a381-722c2a4bd863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['team_1', 'barstool_team_1_prob', 'betfair_team_1_prob',\n",
       "       'betmgm_team_1_prob', 'betonlineag_team_1_prob',\n",
       "       'betrivers_team_1_prob', 'bovada_team_1_prob',\n",
       "       'circasports_team_1_prob', 'draftkings_team_1_prob',\n",
       "       'fanduel_team_1_prob', 'foxbet_team_1_prob', 'gtbets_team_1_prob',\n",
       "       'pinnacle_team_1_prob', 'pointsbetus_team_1_prob',\n",
       "       'sugarhouse_team_1_prob', 'twinspires_team_1_prob',\n",
       "       'unibet_team_1_prob', 'williamhillus_team_1_prob',\n",
       "       'wynnbet_team_1_prob', 'game_id', 'winning_team',\n",
       "       'minutes_since_commence', 'snapshot_time_taken', 'hour_of_start',\n",
       "       'day_of_week', 'home_away', 'barstool_last_update_time',\n",
       "       'betfair_last_update_time', 'betmgm_last_update_time',\n",
       "       'betonlineag_last_update_time', 'betrivers_last_update_time',\n",
       "       'bovada_last_update_time', 'circasports_last_update_time',\n",
       "       'draftkings_last_update_time', 'fanduel_last_update_time',\n",
       "       'foxbet_last_update_time', 'gtbets_last_update_time',\n",
       "       'pinnacle_last_update_time', 'pointsbetus_last_update_time',\n",
       "       'sugarhouse_last_update_time', 'twinspires_last_update_time',\n",
       "       'unibet_last_update_time', 'williamhillus_last_update_time',\n",
       "       'wynnbet_last_update_time', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4198a5c4-410a-41a1-9990-0aa94147f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_category(column_name, data):\n",
    "    \n",
    "    column_index = data.columns.tolist().index(column_name)\n",
    "    \n",
    "    arr = data[column_name].values.reshape(-1,1)\n",
    "    \n",
    "    coder = OneHotEncoder(sparse_output=False)\n",
    "    \n",
    "    onehots = coder.fit_transform(arr)\n",
    "    \n",
    "    print(onehots.shape)\n",
    "    \n",
    "    return onehots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f47e2b58-e372-4faa-987e-973b5b144717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_numeric(column_name, data):\n",
    "    \n",
    "    # Get the index from the full df of the input column name\n",
    "    column_index = data.columns.tolist().index(column_name)\n",
    "    \n",
    "    # Make an array of the column values \n",
    "    arr = data[column_name].values.reshape(-1,1).astype('float')\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "586ff161-3075-44c5-a4a8-492d1e7895ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87562, 30)\n",
      "(87562, 9)\n",
      "(87562, 7)\n"
     ]
    }
   ],
   "source": [
    "data = df\n",
    "full_data = np.concatenate(\n",
    "    [\n",
    "        add_numeric('barstool_team_1_prob', data),\n",
    "        add_numeric('betfair_team_1_prob', data),\n",
    "        add_numeric('betmgm_team_1_prob', data),\n",
    "        add_numeric('betonlineag_team_1_prob', data),\n",
    "        add_numeric('betrivers_team_1_prob', data),\n",
    "        add_numeric('bovada_team_1_prob', data),\n",
    "        add_numeric('circasports_team_1_prob', data),\n",
    "        add_numeric('draftkings_team_1_prob', data),\n",
    "        add_numeric('fanduel_team_1_prob', data),\n",
    "        add_numeric('foxbet_team_1_prob', data),\n",
    "        add_numeric('gtbets_team_1_prob', data),\n",
    "        add_numeric('pinnacle_team_1_prob', data),\n",
    "        add_numeric('pointsbetus_team_1_prob', data),\n",
    "        add_numeric('sugarhouse_team_1_prob', data),\n",
    "        add_numeric('twinspires_team_1_prob', data),\n",
    "        add_numeric('unibet_team_1_prob', data),\n",
    "        add_numeric('williamhillus_team_1_prob', data),\n",
    "        add_numeric('wynnbet_team_1_prob', data),\n",
    "        add_numeric('minutes_since_commence', data),\n",
    "        add_numeric('home_away', data),\n",
    "        add_category('team_1', data),\n",
    "        add_category('hour_of_start', data),\n",
    "        add_category('day_of_week', data)\n",
    "    ],\n",
    "    1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ccdeee40-2e0e-4753-ab80-5ba4a82b4322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71600, 30)\n",
      "(71600, 9)\n",
      "(71600, 7)\n"
     ]
    }
   ],
   "source": [
    "data = df_80_percent\n",
    "train_data = np.concatenate(\n",
    "    [\n",
    "        add_numeric('barstool_team_1_prob', data),\n",
    "        add_numeric('betfair_team_1_prob', data),\n",
    "        add_numeric('betmgm_team_1_prob', data),\n",
    "        add_numeric('betonlineag_team_1_prob', data),\n",
    "        add_numeric('betrivers_team_1_prob', data),\n",
    "        add_numeric('bovada_team_1_prob', data),\n",
    "        add_numeric('circasports_team_1_prob', data),\n",
    "        add_numeric('draftkings_team_1_prob', data),\n",
    "        add_numeric('fanduel_team_1_prob', data),\n",
    "        add_numeric('foxbet_team_1_prob', data),\n",
    "        add_numeric('gtbets_team_1_prob', data),\n",
    "        add_numeric('pinnacle_team_1_prob', data),\n",
    "        add_numeric('pointsbetus_team_1_prob', data),\n",
    "        add_numeric('sugarhouse_team_1_prob', data),\n",
    "        add_numeric('twinspires_team_1_prob', data),\n",
    "        add_numeric('unibet_team_1_prob', data),\n",
    "        add_numeric('williamhillus_team_1_prob', data),\n",
    "        add_numeric('wynnbet_team_1_prob', data),\n",
    "        add_numeric('minutes_since_commence', data),\n",
    "        add_numeric('home_away', data),\n",
    "        add_category('team_1', data),\n",
    "        add_category('hour_of_start', data),\n",
    "        add_category('day_of_week', data)\n",
    "    ],\n",
    "    1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5e16e080-a899-4720-ae0c-ea0d46d6f70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15962, 30)\n",
      "(15962, 9)\n",
      "(15962, 7)\n"
     ]
    }
   ],
   "source": [
    "data = df_20_percent\n",
    "test_data = np.concatenate(\n",
    "    [\n",
    "        add_numeric('barstool_team_1_prob', data),\n",
    "        add_numeric('betfair_team_1_prob', data),\n",
    "        add_numeric('betmgm_team_1_prob', data),\n",
    "        add_numeric('betonlineag_team_1_prob', data),\n",
    "        add_numeric('betrivers_team_1_prob', data),\n",
    "        add_numeric('bovada_team_1_prob', data),\n",
    "        add_numeric('circasports_team_1_prob', data),\n",
    "        add_numeric('draftkings_team_1_prob', data),\n",
    "        add_numeric('fanduel_team_1_prob', data),\n",
    "        add_numeric('foxbet_team_1_prob', data),\n",
    "        add_numeric('gtbets_team_1_prob', data),\n",
    "        add_numeric('pinnacle_team_1_prob', data),\n",
    "        add_numeric('pointsbetus_team_1_prob', data),\n",
    "        add_numeric('sugarhouse_team_1_prob', data),\n",
    "        add_numeric('twinspires_team_1_prob', data),\n",
    "        add_numeric('unibet_team_1_prob', data),\n",
    "        add_numeric('williamhillus_team_1_prob', data),\n",
    "        add_numeric('wynnbet_team_1_prob', data),\n",
    "        add_numeric('minutes_since_commence', data),\n",
    "        add_numeric('home_away', data),\n",
    "        add_category('team_1', data),\n",
    "        add_category('hour_of_start', data),\n",
    "        add_category('day_of_week', data)\n",
    "    ],\n",
    "    1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "36ce04d2-f2c9-4bf3-84ad-b351355da5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87562, 66)\n",
      "(71600, 66)\n",
      "(15962, 66)\n"
     ]
    }
   ],
   "source": [
    "print(full_data.shape)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e006675c-e96b-479f-8ed2-2eaacb72a2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the indices of the columns you want to standardize\n",
    "continuous_vars_full = full_data[:, :19]\n",
    "continuous_vars_test = test_data[:, :19]\n",
    "continuous_vars_train = train_data[:, :19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4a7e364d-ba18-49f3-89a0-7032f30fe5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of StandardScaler and fit it on the training data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(continuous_vars_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "475f7eac-083b-4332-b2e0-537753254d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the columns of the training data\n",
    "X_train = np.hstack((scaler.transform(continuous_vars_train), train_data[:, 19:-1]))\n",
    "X_test = np.hstack((scaler.transform(continuous_vars_test), test_data[:, 19:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5735168a-0cc9-4ec2-9e3e-0eb8a49e0973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65,)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "254bb6e7-2856-4a37-89ad-c8ce95b2e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make our y var\n",
    "y_train = df_80_percent['target'].values\n",
    "y_test = df_20_percent['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c0f3721d-7ea2-4112-a2f1-78f5d07ed5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Torch datasets with our splits\n",
    "train_data = torch.utils.data.TensorDataset(torch.tensor(X_train).float(), torch.tensor(y_train).float())\n",
    "test_data = torch.utils.data.TensorDataset(torch.tensor(X_test).float(), torch.tensor(y_test).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1894c9bd-ade7-47ef-9a65-45cce1836c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up loaders for each of our datasets \n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size = 64, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "510a2e49-65ea-4b6a-a1a9-0cdb8a34cf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the layers and activation functions of our model\n",
    "# model = torch.nn.Sequential(   \n",
    "#     torch.nn.Linear(65,256),\n",
    "#     torch.nn.SiLU(),\n",
    "#     torch.nn.Linear(256,128),\n",
    "#     torch.nn.SiLU(),\n",
    "#     torch.nn.Linear(128,64),\n",
    "#     torch.nn.SiLU(),\n",
    "#     torch.nn.Linear(64,64),\n",
    "#     torch.nn.SiLU(),\n",
    "#     torch.nn.Linear(64,16),\n",
    "#     torch.nn.SiLU(),\n",
    "#     torch.nn.Linear(16,1)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "151bc190-5357-4fa6-ba2a-842a0d69b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the layers and activation functions of our model\n",
    "model = torch.nn.Sequential(   \n",
    "    torch.nn.Linear(65,800),\n",
    "    torch.nn.SiLU(),\n",
    "    torch.nn.Linear(800,800),\n",
    "    torch.nn.SiLU(),\n",
    "    torch.nn.Linear(800,800),\n",
    "    torch.nn.SiLU(),\n",
    "    torch.nn.Linear(800,800),\n",
    "    torch.nn.SiLU(),\n",
    "    torch.nn.Linear(800,256),\n",
    "    torch.nn.SiLU(),\n",
    "    torch.nn.Linear(256,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e2551905-6e36-4219-bf87-b7518277eaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66832"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_count = (65*800)+(800*800)+(800*800)+(800*800)+(800*256)+256\n",
    "params_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "3943e9c8-af08-45db-bc6d-ad7b28e5aae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines our scoring function\n",
    "def scoring_function(pred, label):\n",
    "    return nn.functional.binary_cross_entropy_with_logits(pred, label)\n",
    "\n",
    "# Defines number of epochs we want to train through\n",
    "num_epochs = 25\n",
    "\n",
    "# Defines our optimizer and the learning rate \n",
    "optimizer = torch.optim.Adam( model.parameters(), lr=.001  )#, weight_decay=.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4425cb01-94bd-41dd-a102-f3ea5ef78e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_epoch_ev(wpp, avg_odds):\n",
    "    profit_if_win = (100*(1/avg_odds))- 100\n",
    "    return ((profit_if_win * wpp) - ((1-wpp)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "fe431f8d-9002-4e9d-8962-4d8fe2b424f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Initializes a list that will contain our batch losses for an individual epoch\n",
    "    epoch_losses = []\n",
    "    \n",
    "    # Defines how we want to step through each batch in the epoch\n",
    "    for batch in train_loader:\n",
    "        \n",
    "        # Resets the gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Prepare the input and output tensors for the current batch\n",
    "        batchX = torch.tensor(batch[0], dtype=torch.float32)\n",
    "        batchY = torch.tensor(batch[1], dtype=torch.float32)\n",
    "        \n",
    "        # Forward pass\n",
    "        y_pred = model.forward(batchX)\n",
    "        batchY = batchY.unsqueeze(1)  # Reshape to (batch_size, 1)\n",
    "        \n",
    "        # Compute the loss with weighted BCEWithLogitsLoss\n",
    "        pos_weight = torch.tensor([5.0])  # higher weight for positive class\n",
    "        \n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "        loss = criterion(y_pred, batchY)\n",
    "        \n",
    "        # Store the loss for this batch in the list\n",
    "        epoch_losses.append(loss.detach().clone())\n",
    "\n",
    "        # Compute the gradient of the error with respect to the model parameters\n",
    "        loss.mean().backward()\n",
    "\n",
    "        # update the model parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    all_epoch_loss = torch.tensor(epoch_losses)\n",
    "    epoch_loss = torch.mean(all_epoch_loss)\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "04109a9f-401f-485c-be10-b990a3323b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model():\n",
    "    # Put model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Initialize counters\n",
    "    hit_count = 0\n",
    "    win_preds_count = 0\n",
    "    win_pred_hit = 0\n",
    "    mean_odds_list = np.array([])\n",
    "    \n",
    "    # Initialize y_test\n",
    "    y_test = []\n",
    "\n",
    "    # Loop over the test data\n",
    "    for batch in test_loader:\n",
    "        # Prepare the input and output tensors for the current batch\n",
    "        batchX = torch.tensor(batch[0], dtype=torch.float32)\n",
    "        batchY = torch.tensor(batch[1], dtype=torch.float32)\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = model(batchX)\n",
    "\n",
    "        # Apply threshold\n",
    "        predictions = torch.where(predictions > 0.75, 1, 0)\n",
    "\n",
    "        # Count the number of positive predictions\n",
    "        win_preds_count += torch.sum(predictions == 1).item()\n",
    "\n",
    "        # Add the labels of the current batch to y_test\n",
    "        y_test.extend(batchY.tolist())\n",
    "\n",
    "        # Count the number of correctly predicted positive cases\n",
    "        for i in range(len(predictions)):\n",
    "            if predictions[i].item() == 1 and batchY[i].item() == 1:\n",
    "                win_pred_hit += 1\n",
    "            if predictions[i].item() == batchY[i].item():\n",
    "                hit_count += 1\n",
    "        \n",
    "        # Filter batchX by positive predictions\n",
    "        idx = predictions.squeeze() == 1\n",
    "        \n",
    "        batchX_test_scaled = scaler.inverse_transform(batchX[:, :19])\n",
    "        \n",
    "        batchX_test_scaled_tensor = torch.from_numpy(batchX_test_scaled)\n",
    "        \n",
    "        batchX_pos = batchX_test_scaled_tensor.masked_select(idx.unsqueeze(-1)).view(-1, 19)\n",
    "        \n",
    "        batchX_pos_first_col = batchX_pos[:, 0]\n",
    "        \n",
    "        batchX_pos_gt = batchX_pos_first_col[torch.gt(batchX_pos_first_col, .001)]\n",
    "        \n",
    "        mean_batch_odds = torch.mean(batchX_pos_gt)\n",
    "        \n",
    "        mean_odds_list = np.append(mean_odds_list, mean_batch_odds)\n",
    "        \n",
    "            \n",
    "    # Convert y_test to a tensor\n",
    "    y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "    # Compute hit percentage and accuracy of win predictions\n",
    "    hit_percent = hit_count / len(test_data)\n",
    "    win_pred_accuracy = win_pred_hit / win_preds_count if win_pred_hit > 0 and win_preds_count > 0 else 0\n",
    "    \n",
    "    ev = calc_epoch_ev(win_pred_accuracy, np.mean(mean_odds_list))\n",
    "\n",
    "    # Return the results\n",
    "    return hit_percent, win_pred_accuracy, win_preds_count, np.mean(mean_odds_list), ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "f22a687b-095d-4df9-a8a2-7cc270b856e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, Loss: 1.0068098306655884, Acc:  66.119534%, WP Acc:  61.514365%, WPs: 11173, Avg Odds: 0.5966671508912762, EV: 3.0966174275468674\n",
      "Epoch : 2, Loss: 0.9598028659820557, Acc:  65.405338%, WP Acc:  60.941532%, WPs: 11237, Avg Odds: 0.582149436032868, EV: 4.6836579500569755\n",
      "Epoch : 3, Loss: 0.862000048160553, Acc:  64.164892%, WP Acc:  60.010626%, WPs: 11293, Avg Odds: 0.5749679901488706, EV: 4.3721164999088415\n",
      "Epoch : 4, Loss: 0.6740446090698242, Acc:  67.842376%, WP Acc:  64.220092%, WPs: 10014, Avg Odds: 0.5947613964104749, EV: 7.976227540932307\n",
      "Epoch : 5, Loss: 0.4726661741733551, Acc:  65.467986%, WP Acc:  63.213101%, WPs: 9343, Avg Odds: 0.5893542867424986, EV: 7.258235223006984\n",
      "Epoch : 6, Loss: 0.3300187885761261, Acc:  66.276156%, WP Acc:  63.534070%, WPs: 9598, Avg Odds: 0.5907511126329554, EV: 7.547947416745323\n",
      "Epoch : 7, Loss: 0.2581048011779785, Acc:  65.192332%, WP Acc:  64.071022%, WPs: 8617, Avg Odds: 0.5928521794439895, EV: 8.072508829562906\n",
      "Epoch : 8, Loss: 0.22219641506671906, Acc:  64.753790%, WP Acc:  63.035536%, WPs: 9033, Avg Odds: 0.5879058330868573, EV: 7.2204642632670115\n",
      "Epoch : 9, Loss: 0.1974439024925232, Acc:  63.012154%, WP Acc:  62.690945%, WPs: 8183, Avg Odds: 0.591985034316111, EV: 5.899543075025711\n",
      "Epoch : 10, Loss: 0.1822037547826767, Acc:  65.618344%, WP Acc:  64.587478%, WPs: 8545, Avg Odds: 0.5936918309261054, EV: 8.789568413957909\n",
      "Epoch : 11, Loss: 0.17297840118408203, Acc:  65.455457%, WP Acc:  64.742441%, WPs: 8367, Avg Odds: 0.5937330523752028, EV: 9.043012312045363\n",
      "Epoch : 12, Loss: 0.16570359468460083, Acc:  63.538404%, WP Acc:  62.758295%, WPs: 8469, Avg Odds: 0.5791949249627019, EV: 8.354359220471139\n",
      "Epoch : 13, Loss: 0.1514742523431778, Acc:  64.722466%, WP Acc:  63.084633%, WPs: 8980, Avg Odds: 0.5922148102646518, EV: 6.523226746916755\n",
      "Epoch : 14, Loss: 0.15090641379356384, Acc:  64.941737%, WP Acc:  63.778163%, WPs: 8655, Avg Odds: 0.5922831727126436, EV: 7.681875579056587\n",
      "Epoch : 15, Loss: 0.145751491189003, Acc:  64.189951%, WP Acc:  63.334511%, WPs: 8493, Avg Odds: 0.5921594605202268, EV: 6.955161567354338\n",
      "Epoch : 16, Loss: 0.14040523767471313, Acc:  64.434281%, WP Acc:  62.822796%, WPs: 8984, Avg Odds: 0.5901947070430914, EV: 6.44418754053072\n",
      "Epoch : 17, Loss: 0.13691659271717072, Acc:  64.916677%, WP Acc:  64.231919%, WPs: 8365, Avg Odds: 0.6028902108425507, EV: 6.539992777691332\n",
      "Epoch : 18, Loss: 0.1274055391550064, Acc:  64.428017%, WP Acc:  64.518976%, WPs: 7931, Avg Odds: 0.5990409758205064, EV: 7.70377782770197\n",
      "Epoch : 19, Loss: 0.13153919577598572, Acc:  65.467986%, WP Acc:  64.811038%, WPs: 8335, Avg Odds: 0.5937687993192969, EV: 9.151976100363648\n",
      "Epoch : 20, Loss: 0.11940062791109085, Acc:  64.860293%, WP Acc:  64.309846%, WPs: 8288, Avg Odds: 0.5915074643487437, EV: 8.721951008093207\n",
      "Epoch : 21, Loss: 0.12320197373628616, Acc:  65.493046%, WP Acc:  64.771234%, WPs: 8371, Avg Odds: 0.5977914131836053, EV: 8.35089396362035\n",
      "Epoch : 22, Loss: 0.12519435584545135, Acc:  63.814058%, WP Acc:  63.243243%, WPs: 8325, Avg Odds: 0.5917004663685494, EV: 6.88388270400862\n",
      "Epoch : 23, Loss: 0.1115885078907013, Acc:  63.983210%, WP Acc:  63.911743%, WPs: 8022, Avg Odds: 0.5905563019931196, EV: 8.222945876376158\n",
      "Epoch : 24, Loss: 0.11903971433639526, Acc:  63.970680%, WP Acc:  63.401442%, WPs: 8320, Avg Odds: 0.5938561712186902, EV: 6.762285853798865\n",
      "Epoch : 25, Loss: 0.10600802302360535, Acc:  63.964415%, WP Acc:  63.589806%, WPs: 8201, Avg Odds: 0.5946199555319024, EV: 6.941930773786524\n"
     ]
    }
   ],
   "source": [
    "# Calls the train function for each of our epochs, prints the running results\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    ep_result = train()\n",
    "    \n",
    "    hit_percent, win_pred_accuracy, win_preds_count, avg_odds, ev = test_model()\n",
    "    \n",
    "    print(f'Epoch : {epoch + 1}, Loss: {ep_result}, Acc: {hit_percent: %}, WP Acc: {win_pred_accuracy: 2%}, WPs: {win_preds_count}, Avg Odds: {avg_odds}, EV: {ev}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "554dbcee-2ae6-4855-af9f-a65897dcc8be",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m teams \u001b[38;5;241m=\u001b[39m \u001b[43mtest_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m49\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py4sci/lib/python3.10/site-packages/torch/utils/data/dataset.py:188\u001b[0m, in \u001b[0;36mTensorDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py4sci/lib/python3.10/site-packages/torch/utils/data/dataset.py:188\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "teams = test_data[:, 20:49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c68291-b93c-4164-a875-2ed7b4bd9442",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adecfde7-dac8-4c9e-9908-bbb6e235f1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the counts for each category\n",
    "counts = np.sum(teams, axis=0)\n",
    "\n",
    "print(counts)\n",
    "\n",
    "# Plot the distribution using a bar chart\n",
    "labels = [i for i in range(30)]\n",
    "plt.bar(labels, counts)\n",
    "plt.title('Distribution of Categorical Data')\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()\n",
    "\n",
    "# Plot the distribution using a histogram\n",
    "categories = np.argmax(one_hot_data, axis=1)\n",
    "plt.hist(categories, bins=3, align='left', rwidth=0.5)\n",
    "plt.xticks([0, 1, 2], labels)\n",
    "plt.title('Distribution of Categorical Data')\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2b9ecb-5375-4abe-b84d-003a3d3411d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(y_test)  # convert y_test to a numpy array\n",
    "counts_1 = np.sum(teams[y_test.astype(int) == 1], axis=0)\n",
    "counts_0 = np.sum(teams[y_test.astype(int) == 0], axis=0)\n",
    "counts = np.sum(teams, axis=0)\n",
    "\n",
    "print(counts_1)\n",
    "print(counts_0)\n",
    "print(counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0e2967-6334-450d-98c3-041d6aaf48b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot bars in stack manner\n",
    "x = [i for i in range(30)]\n",
    "plt.bar(x, counts_1, color='r')\n",
    "#plt.bar(x, counts_0, bottom=counts_1, color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0a539f-b320-4590-9f02-1715bd2655cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
